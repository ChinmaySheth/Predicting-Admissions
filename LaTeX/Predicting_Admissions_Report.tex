\documentclass{article}

\usepackage{amsfonts}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{hyperref}
\graphicspath{ {images/} }

\title{Predicting Admissions}
\author{Chinmay Sheth}
 \date\today
%This information doesn't actually show up on your document unless you use the maketitle command below

\begin{document}

\maketitle

\section*{Introduction}

In this exercise, I'm analyzing a university dataset which contains information about student admissions. I am hoping to build a generalized linear model in order to reliably predict a student's admission to the university using SAS.

\section*{Dataset}

The \href{https://www.kaggle.com/mohansacharya/graduate-admissions}{dataset} that I am using was obtained from Kaggle and it contains data on university admission data. The dataset contains the following columns:

\begin{enumerate}

\item Serial No.
\item GRE Score
\item TOEFL Score
\item University Rating
\item SOP
\item LOR
\item CGPA
\item Research
\item Chance of Admit

\end{enumerate}

\section*{Data Exploration}

The dataset contains 400 entries with no data missing. The only categorical variable in the dataset is "Research" which has two values, 1 if the applicant has done research and 0 if they haven't. Otherwise, all the other variables are continuous.

\section*{Analysis}
\subsection*{Diagnostics}

Through the PROC GLM function, SAS is easily able to build a basic linear model that considers all the variables with interactions, which can be further investigated to determine to see if the linear regression assumption are met. PROC GLM is also able to differentiate between categorical and continuous variables by indicating so in the CLASS definition of the function. As such, "Research" is specified as a categorical variable in the CLASS method, and "SERIAL NO." is not included since it provides no significant meaning as they are all random.

In the diagnostic plots from Figure \ref{fig:basicmodeldiagnostics} there is a departure from the homoskedasticity assumption, that is of constant variance throughout the data, because of the decreasing variance in the data in the Residual vs Predicted Value plot and RStudent vs Predicted Value plot. There also appears to be a departure from the assumption of the expected value of the residuals to equal zero as the data in the two aforementioned plots is not centred around the horizontal zero axis. Finally, the data does not appear to be normally distributed as the Residual vs Quantile Plot shows that the points are not very closely hugging the reference line.

\subsection*{Transformations}
Using the data-driven Box-Cox technique, showed in Figure \ref{fig:boxcoxanalysis}, we can estimate the best transformation for the basic linear model which should result in diagnostic plots which have less of a departure from the linear regression assumptions. The R-Squared value has increased from 0.807246 (Figure \ref{fig:basicmodeloutput}) to 0.860190 in the transformed model, indicating that the transformed model is able to explain more variability in the predicted values than the initial model was able to. Furthermore, there appears to be a significantly less departure from the linear regression assumptions as is seen in the diagnostic plots.

\subsection*{Model Selection}

Now that the regression assumptions have been satisfied, model selection can be performed in order to determine whether all the covariates are truly necessary. According to the \href{https://www.oxfordreference.com/view/10.1093/oi/authority.20110803100346221}{Principle of Parsimony}, we want to be able to explain the variability in the model with the fewest covariates possible, that is, we want to maximize the Adjusted R-squared value while having the fewest number of covariate. In SAS, the GLMSELECT procedure with BIC can be used in order to select the best model. 

The results of this are presented in Figure \ref{fig:bic} which shows that only the following covariates are meaningful to the model:

\begin{enumerate}

\item GRE Score
\item TOEFL Score
\item LOR
\item Research
\item CGPA * Research (Interaction Term)
\item University Rating * Research (Interaction Term)

\end{enumerate}

\section*{Conclusion}

Overall in this exercise, using SAS, we determined that not all of the covariates that were provided were important in model selection. Furthermore, 85.67\% of the variability in the predicted values could be explained with the reduced model that was determined with BIC. The reduced model resulted in an increase in the Adjusted R-Squared value of 4.95\%. 

\newpage
\begin{figure}[h!]
\includegraphics[scale=1]{basic_model_output.png}
\caption{Basic model output}
\label{fig:basicmodeloutput}
\end{figure}

\begin{figure}
\includegraphics[scale=1]{basic_model_estimates.png}
\caption{Basic model estimates}
\label{fig:basicmodelestimate}
\end{figure}

\begin{figure}
\centering
\includegraphics[scale=0.7]{basic_model_diagnostics.png}
\caption{Model Diagnostics for Basic Model with Interactions}
\label{fig:basicmodeldiagnostics}
\end{figure}

\begin{figure}
\centering
\includegraphics[scale=0.5]{box_cox_analysis.png}
\caption{Box Cox Analysis for Basic Model with Interactions}
\label{fig:boxcoxanalysis}
\end{figure}

\begin{figure}
\centering
\includegraphics[scale=1]{transformed_model_output.png}
\caption{Transformed Model Output}
\label{fig:transformedmodeloutput}
\end{figure}

\begin{figure}
\centering
\includegraphics[scale=0.7]{transformed_model_diagnostics.png}
\caption{Transformed Model Diagnostics}
\label{fig:transformedmodeldiagnostics}
\end{figure}

\begin{figure}
\centering
\includegraphics[scale=0.7]{bic.png}
\caption{BIC Model Selection}
\label{fig:bic}
\end{figure}

\end{document}
